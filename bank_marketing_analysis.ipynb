{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# IML 1.2 - Análise de Aquisição de Produtos Bancários\n",
        "\n",
        "## Objetivo\n",
        "Desenvolver um modelo de classificação para prever se um cliente irá subscrever (aderir) ao depósito a prazo oferecido pelo banco.\n",
        "\n",
        "## Descrição do Problema\n",
        "Este é um problema de classificação binária onde:\n",
        "- **Variável alvo (y)**: 1 se o cliente subscreveu, 0 se não subscreveu\n",
        "- **Objetivo**: Prever o comportamento de novos usuários\n",
        "- **Desafio**: Base desbalanceada (mais casos negativos que positivos)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Importação de Bibliotecas e Carregamento dos Dados\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
        "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Configuração para visualizações\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "plt.rcParams['figure.figsize'] = (12, 8)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Carregamento dos dados\n",
        "df = pd.read_csv('Unidade 2 - Atividade2.csv', sep=';')\n",
        "\n",
        "print(f\"Dimensões dos dados: {df.shape}\")\n",
        "print(f\"\\nPrimeiras linhas:\")\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Análise Exploratória dos Dados (EDA)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Informações gerais sobre o dataset\n",
        "print(\"=== INFORMAÇÕES GERAIS ===\")\n",
        "print(f\"Número de linhas: {df.shape[0]}\")\n",
        "print(f\"Número de colunas: {df.shape[1]}\")\n",
        "print(f\"\\nTipos de dados:\")\n",
        "print(df.dtypes)\n",
        "\n",
        "print(\"\\n=== VALORES MISSING ===\")\n",
        "missing_values = df.isnull().sum()\n",
        "print(missing_values[missing_values > 0])\n",
        "\n",
        "print(\"\\n=== ESTATÍSTICAS DESCRITIVAS ===\")\n",
        "df.describe()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Análise da variável alvo\n",
        "print(\"=== DISTRIBUIÇÃO DA VARIÁVEL ALVO ===\")\n",
        "target_dist = df['y'].value_counts()\n",
        "print(target_dist)\n",
        "print(f\"\\nProporção de 'sim': {target_dist['yes']/len(df)*100:.2f}%\")\n",
        "print(f\"Proporção de 'não': {target_dist['no']/len(df)*100:.2f}%\")\n",
        "\n",
        "# Visualização da distribuição da variável alvo\n",
        "plt.figure(figsize=(8, 6))\n",
        "target_dist.plot(kind='bar', color=['lightcoral', 'lightblue'])\n",
        "plt.title('Distribuição da Variável Alvo (y)')\n",
        "plt.xlabel('Subscrição')\n",
        "plt.ylabel('Frequência')\n",
        "plt.xticks(rotation=0)\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n=== CONCLUSÃO ===\")\n",
        "print(\"A base está DESBALANCEADA! Há muito mais casos negativos que positivos.\")\n",
        "print(\"Isso deve ser considerado na escolha das métricas de avaliação.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Análise das variáveis categóricas\n",
        "categorical_vars = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'day_of_week', 'poutcome']\n",
        "\n",
        "print(\"=== ANÁLISE DAS VARIÁVEIS CATEGÓRICAS ===\")\n",
        "for var in categorical_vars:\n",
        "    print(f\"\\n{var.upper()}:\")\n",
        "    print(df[var].value_counts())\n",
        "    print(f\"Valores únicos: {df[var].nunique()}\")\n",
        "    \n",
        "    # Verificar se há valores 'unknown'\n",
        "    if 'unknown' in df[var].values:\n",
        "        unknown_count = (df[var] == 'unknown').sum()\n",
        "        print(f\"Valores 'unknown': {unknown_count} ({unknown_count/len(df)*100:.2f}%)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Análise de correlação entre variáveis numéricas e a variável alvo\n",
        "numeric_vars = ['age', 'duration', 'campaign', 'pdays', 'previous', 'emp.var.rate', \n",
        "                'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed']\n",
        "\n",
        "print(\"=== CORRELAÇÃO COM VARIÁVEL ALVO ===\")\n",
        "# Converter variável alvo para numérica temporariamente\n",
        "df_temp = df.copy()\n",
        "df_temp['y_numeric'] = df_temp['y'].map({'yes': 1, 'no': 0})\n",
        "\n",
        "correlations = df_temp[numeric_vars + ['y_numeric']].corr()['y_numeric'].sort_values(ascending=False)\n",
        "print(correlations)\n",
        "\n",
        "# Visualização da correlação\n",
        "plt.figure(figsize=(10, 8))\n",
        "correlations.drop('y_numeric').plot(kind='barh')\n",
        "plt.title('Correlação das Variáveis Numéricas com a Variável Alvo')\n",
        "plt.xlabel('Correlação')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Tratamento e Preparação dos Dados\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Criar cópia dos dados para tratamento\n",
        "df_processed = df.copy()\n",
        "\n",
        "print(\"=== TRATAMENTO DE DADOS ===\")\n",
        "print(\"1. Tratamento de valores 'unknown'\")\n",
        "\n",
        "# Estratégia para valores 'unknown':\n",
        "# - Para 'default': considerar como 'no' (mais conservador)\n",
        "# - Para 'education': considerar como 'basic.4y' (mais comum)\n",
        "# - Para 'job': manter como categoria separada\n",
        "\n",
        "df_processed['default'] = df_processed['default'].replace('unknown', 'no')\n",
        "df_processed['education'] = df_processed['education'].replace('unknown', 'basic.4y')\n",
        "\n",
        "print(\"Valores 'unknown' tratados:\")\n",
        "print(f\"- default: {(df['default'] == 'unknown').sum()} → {(df_processed['default'] == 'unknown').sum()}\")\n",
        "print(f\"- education: {(df['education'] == 'unknown').sum()} → {(df_processed['education'] == 'unknown').sum()}\")\n",
        "print(f\"- job: {(df['job'] == 'unknown').sum()} → mantido como categoria\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2. Tratamento de outliers na variável 'duration'\n",
        "print(\"\\n2. Análise de outliers na variável 'duration'\")\n",
        "\n",
        "# Análise de outliers usando IQR\n",
        "Q1 = df_processed['duration'].quantile(0.25)\n",
        "Q3 = df_processed['duration'].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "lower_bound = Q1 - 1.5 * IQR\n",
        "upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "outliers = df_processed[(df_processed['duration'] < lower_bound) | (df_processed['duration'] > upper_bound)]\n",
        "print(f\"Outliers detectados: {len(outliers)} ({len(outliers)/len(df_processed)*100:.2f}%)\")\n",
        "print(f\"Limites: [{lower_bound:.0f}, {upper_bound:.0f}]\")\n",
        "\n",
        "# Visualização da distribuição de duration\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.hist(df_processed['duration'], bins=50, alpha=0.7, color='skyblue')\n",
        "plt.title('Distribuição de Duration')\n",
        "plt.xlabel('Duration (segundos)')\n",
        "plt.ylabel('Frequência')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.boxplot(df_processed['duration'])\n",
        "plt.title('Boxplot de Duration')\n",
        "plt.ylabel('Duration (segundos)')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Decisão: manter outliers pois podem ser importantes para o modelo\n",
        "print(\"Decisão: Manter outliers - podem representar casos importantes de longas conversas\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3. Encoding de variáveis categóricas\n",
        "print(\"\\n3. Encoding de variáveis categóricas\")\n",
        "\n",
        "# Variáveis binárias (já estão em formato adequado)\n",
        "binary_vars = ['default', 'housing', 'loan']\n",
        "print(f\"Variáveis binárias mantidas: {binary_vars}\")\n",
        "\n",
        "# Variáveis categóricas que precisam de encoding\n",
        "categorical_vars_to_encode = ['job', 'marital', 'education', 'contact', 'month', 'day_of_week', 'poutcome']\n",
        "\n",
        "# Aplicar Label Encoding\n",
        "label_encoders = {}\n",
        "for var in categorical_vars_to_encode:\n",
        "    le = LabelEncoder()\n",
        "    df_processed[var + '_encoded'] = le.fit_transform(df_processed[var])\n",
        "    label_encoders[var] = le\n",
        "    print(f\"{var}: {len(le.classes_)} categorias → {var}_encoded\")\n",
        "\n",
        "# Converter variável alvo para numérica\n",
        "df_processed['y_numeric'] = df_processed['y'].map({'yes': 1, 'no': 0})\n",
        "\n",
        "print(f\"\\nVariável alvo convertida: y → y_numeric (1=sim, 0=não)\")\n",
        "print(f\"Distribuição: {df_processed['y_numeric'].value_counts().to_dict()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4. Preparação do dataset final para modelagem\n",
        "print(\"\\n4. Preparação do dataset final\")\n",
        "\n",
        "# Selecionar features para o modelo\n",
        "feature_columns = (numeric_vars + \n",
        "                  [var + '_encoded' for var in categorical_vars_to_encode] + \n",
        "                  binary_vars)\n",
        "\n",
        "X = df_processed[feature_columns]\n",
        "y = df_processed['y_numeric']\n",
        "\n",
        "print(f\"Features selecionadas: {len(feature_columns)}\")\n",
        "print(f\"Shape do dataset: X={X.shape}, y={y.shape}\")\n",
        "\n",
        "# Verificar se há valores missing após o tratamento\n",
        "print(f\"\\nValores missing após tratamento:\")\n",
        "missing_after = X.isnull().sum()\n",
        "print(missing_after[missing_after > 0])\n",
        "\n",
        "# Dividir em treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "print(f\"\\nDivisão treino/teste:\")\n",
        "print(f\"Treino: X={X_train.shape}, y={y_train.shape}\")\n",
        "print(f\"Teste: X={X_test.shape}, y={y_test.shape}\")\n",
        "print(f\"Proporção de classe positiva no treino: {y_train.mean():.3f}\")\n",
        "print(f\"Proporção de classe positiva no teste: {y_test.mean():.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Implementação e Avaliação de Modelos\n",
        "\n",
        "### Considerações para Modelos em Base Desbalanceada:\n",
        "- **Métricas importantes**: Precision, Recall, F1-Score, AUC-ROC, AUC-PR\n",
        "- **Estratégias**: SMOTE, class_weight='balanced', threshold tuning\n",
        "- **Foco**: Identificar corretamente os casos positivos (clientes que vão subscrever)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Normalização dos dados (importante para alguns algoritmos)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(\"Dados normalizados com StandardScaler\")\n",
        "print(f\"Treino: {X_train_scaled.shape}\")\n",
        "print(f\"Teste: {X_test_scaled.shape}\")\n",
        "\n",
        "# Função para avaliar modelos\n",
        "def evaluate_model(model, X_train, X_test, y_train, y_test, model_name):\n",
        "    \\\"\\\"\\\"Função para avaliar um modelo com múltiplas métricas\\\"\\\"\\\"\n",
        "    \n",
        "    # Treinar modelo\n",
        "    model.fit(X_train, y_train)\n",
        "    \n",
        "    # Previsões\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
        "    \n",
        "    # Métricas\n",
        "    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, average_precision_score\n",
        "    \n",
        "    metrics = {\n",
        "        'Modelo': model_name,\n",
        "        'Accuracy': accuracy_score(y_test, y_pred),\n",
        "        'Precision': precision_score(y_test, y_pred),\n",
        "        'Recall': recall_score(y_test, y_pred),\n",
        "        'F1-Score': f1_score(y_test, y_pred),\n",
        "        'AUC-ROC': roc_auc_score(y_test, y_pred_proba),\n",
        "        'AUC-PR': average_precision_score(y_test, y_pred_proba)\n",
        "    }\n",
        "    \n",
        "    return metrics, y_pred, y_pred_proba\n",
        "\n",
        "print(\"Função de avaliação criada com sucesso!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. Regressão Logística\n",
        "print(\"=== MODELO 1: REGRESSÃO LOGÍSTICA ===\")\n",
        "\n",
        "# Regressão Logística com class_weight='balanced' para lidar com desbalanceamento\n",
        "lr_model = LogisticRegression(random_state=42, class_weight='balanced', max_iter=1000)\n",
        "\n",
        "metrics_lr, y_pred_lr, y_pred_proba_lr = evaluate_model(\n",
        "    lr_model, X_train_scaled, X_test_scaled, y_train, y_test, 'Regressão Logística'\n",
        ")\n",
        "\n",
        "print(\"Métricas da Regressão Logística:\")\n",
        "for key, value in metrics_lr.items():\n",
        "    if key != 'Modelo':\n",
        "        print(f\"{key}: {value:.4f}\")\n",
        "\n",
        "# Matriz de confusão\n",
        "plt.figure(figsize=(8, 6))\n",
        "cm_lr = confusion_matrix(y_test, y_pred_lr)\n",
        "sns.heatmap(cm_lr, annot=True, fmt='d', cmap='Blues', \n",
        "            xticklabels=['Não', 'Sim'], yticklabels=['Não', 'Sim'])\n",
        "plt.title('Matriz de Confusão - Regressão Logística')\n",
        "plt.ylabel('Real')\n",
        "plt.xlabel('Predito')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2. Random Forest\n",
        "print(\"=== MODELO 2: RANDOM FOREST ===\")\n",
        "\n",
        "# Random Forest com class_weight='balanced'\n",
        "rf_model = RandomForestClassifier(\n",
        "    n_estimators=100, \n",
        "    random_state=42, \n",
        "    class_weight='balanced',\n",
        "    max_depth=10,\n",
        "    min_samples_split=5,\n",
        "    min_samples_leaf=2\n",
        ")\n",
        "\n",
        "metrics_rf, y_pred_rf, y_pred_proba_rf = evaluate_model(\n",
        "    rf_model, X_train, X_test, y_train, y_test, 'Random Forest'\n",
        ")\n",
        "\n",
        "print(\"Métricas do Random Forest:\")\n",
        "for key, value in metrics_rf.items():\n",
        "    if key != 'Modelo':\n",
        "        print(f\"{key}: {value:.4f}\")\n",
        "\n",
        "# Importância das features\n",
        "feature_importance = pd.DataFrame({\n",
        "    'feature': feature_columns,\n",
        "    'importance': rf_model.feature_importances_\n",
        "}).sort_values('importance', ascending=False)\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.barplot(data=feature_importance.head(15), x='importance', y='feature')\n",
        "plt.title('Top 15 Features Mais Importantes - Random Forest')\n",
        "plt.xlabel('Importância')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\\\nTop 10 features mais importantes:\")\n",
        "print(feature_importance.head(10))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3. Gradient Boosting\n",
        "print(\"=== MODELO 3: GRADIENT BOOSTING ===\")\n",
        "\n",
        "# Gradient Boosting com class_weight='balanced'\n",
        "gb_model = GradientBoostingClassifier(\n",
        "    n_estimators=100,\n",
        "    learning_rate=0.1,\n",
        "    max_depth=6,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "metrics_gb, y_pred_gb, y_pred_proba_gb = evaluate_model(\n",
        "    gb_model, X_train, X_test, y_train, y_test, 'Gradient Boosting'\n",
        ")\n",
        "\n",
        "print(\"Métricas do Gradient Boosting:\")\n",
        "for key, value in metrics_gb.items():\n",
        "    if key != 'Modelo':\n",
        "        print(f\"{key}: {value:.4f}\")\n",
        "\n",
        "# Curva ROC\n",
        "plt.figure(figsize=(8, 6))\n",
        "fpr, tpr, _ = roc_curve(y_test, y_pred_proba_gb)\n",
        "plt.plot(fpr, tpr, label=f'Gradient Boosting (AUC = {metrics_gb[\"AUC-ROC\"]:.3f})')\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Classifier')\n",
        "plt.xlabel('Taxa de Falsos Positivos')\n",
        "plt.ylabel('Taxa de Verdadeiros Positivos')\n",
        "plt.title('Curva ROC - Gradient Boosting')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4. SVM (Support Vector Machine)\n",
        "print(\"=== MODELO 4: SUPPORT VECTOR MACHINE ===\")\n",
        "\n",
        "# SVM com class_weight='balanced'\n",
        "svm_model = SVC(\n",
        "    kernel='rbf',\n",
        "    probability=True,\n",
        "    random_state=42,\n",
        "    class_weight='balanced',\n",
        "    C=1.0,\n",
        "    gamma='scale'\n",
        ")\n",
        "\n",
        "metrics_svm, y_pred_svm, y_pred_proba_svm = evaluate_model(\n",
        "    svm_model, X_train_scaled, X_test_scaled, y_train, y_test, 'SVM'\n",
        ")\n",
        "\n",
        "print(\"Métricas do SVM:\")\n",
        "for key, value in metrics_svm.items():\n",
        "    if key != 'Modelo':\n",
        "        print(f\"{key}: {value:.4f}\")\n",
        "\n",
        "# Comparação de todos os modelos\n",
        "print(\"\\\\n=== COMPARAÇÃO DE TODOS OS MODELOS ===\")\n",
        "all_metrics = [metrics_lr, metrics_rf, metrics_gb, metrics_svm]\n",
        "comparison_df = pd.DataFrame(all_metrics)\n",
        "\n",
        "# Remover coluna 'Modelo' para visualização\n",
        "metrics_comparison = comparison_df.drop('Modelo', axis=1)\n",
        "metrics_comparison.index = comparison_df['Modelo']\n",
        "\n",
        "print(metrics_comparison.round(4))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualização comparativa das métricas\n",
        "plt.figure(figsize=(15, 10))\n",
        "\n",
        "metrics_to_plot = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'AUC-ROC', 'AUC-PR']\n",
        "colors = ['skyblue', 'lightcoral', 'lightgreen', 'gold', 'plum', 'orange']\n",
        "\n",
        "for i, metric in enumerate(metrics_to_plot):\n",
        "    plt.subplot(2, 3, i+1)\n",
        "    bars = plt.bar(comparison_df['Modelo'], comparison_df[metric], color=colors[i])\n",
        "    plt.title(f'{metric}')\n",
        "    plt.ylabel(metric)\n",
        "    plt.xticks(rotation=45)\n",
        "    \n",
        "    # Adicionar valores nas barras\n",
        "    for bar in bars:\n",
        "        height = bar.get_height()\n",
        "        plt.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
        "                f'{height:.3f}', ha='center', va='bottom')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\\\n=== ANÁLISE DAS MÉTRICAS ===\")\n",
        "print(\"Para uma base desbalanceada, as métricas mais importantes são:\")\n",
        "print(\"1. AUC-ROC: Capacidade geral de discriminação\")\n",
        "print(\"2. AUC-PR: Precisão média (melhor para classes desbalanceadas)\")\n",
        "print(\"3. Recall: Capacidade de identificar casos positivos\")\n",
        "print(\"4. F1-Score: Equilíbrio entre precisão e recall\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Curvas ROC comparativas\n",
        "plt.figure(figsize=(10, 8))\n",
        "\n",
        "models_data = [\n",
        "    (y_pred_proba_lr, 'Regressão Logística', metrics_lr['AUC-ROC']),\n",
        "    (y_pred_proba_rf, 'Random Forest', metrics_rf['AUC-ROC']),\n",
        "    (y_pred_proba_gb, 'Gradient Boosting', metrics_gb['AUC-ROC']),\n",
        "    (y_pred_proba_svm, 'SVM', metrics_svm['AUC-ROC'])\n",
        "]\n",
        "\n",
        "for y_pred_proba, model_name, auc_score in models_data:\n",
        "    fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
        "    plt.plot(fpr, tpr, label=f'{model_name} (AUC = {auc_score:.3f})')\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Classifier')\n",
        "plt.xlabel('Taxa de Falsos Positivos')\n",
        "plt.ylabel('Taxa de Verdadeiros Positivos')\n",
        "plt.title('Curvas ROC Comparativas')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "# Curvas Precision-Recall comparativas\n",
        "plt.figure(figsize=(10, 8))\n",
        "\n",
        "for y_pred_proba, model_name, _ in models_data:\n",
        "    precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)\n",
        "    avg_precision = average_precision_score(y_test, y_pred_proba)\n",
        "    plt.plot(recall, precision, label=f'{model_name} (AP = {avg_precision:.3f})')\n",
        "\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Curvas Precision-Recall Comparativas')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ranking dos modelos por diferentes critérios\n",
        "print(\"=== RANKING DOS MODELOS ===\")\n",
        "\n",
        "# Criar DataFrame com rankings\n",
        "ranking_df = pd.DataFrame({\n",
        "    'Modelo': comparison_df['Modelo'],\n",
        "    'AUC-ROC': comparison_df['AUC-ROC'].rank(ascending=False),\n",
        "    'AUC-PR': comparison_df['AUC-PR'].rank(ascending=False),\n",
        "    'F1-Score': comparison_df['F1-Score'].rank(ascending=False),\n",
        "    'Recall': comparison_df['Recall'].rank(ascending=False),\n",
        "    'Precision': comparison_df['Precision'].rank(ascending=False)\n",
        "})\n",
        "\n",
        "print(\"Ranking (1 = melhor):\")\n",
        "print(ranking_df)\n",
        "\n",
        "# Score composto (média dos rankings das métricas mais importantes)\n",
        "important_metrics = ['AUC-ROC', 'AUC-PR', 'F1-Score', 'Recall']\n",
        "ranking_df['Score_Composto'] = ranking_df[important_metrics].mean(axis=1)\n",
        "ranking_df = ranking_df.sort_values('Score_Composto')\n",
        "\n",
        "print(\"\\\\n=== MELHOR MODELO ===\")\n",
        "best_model_name = ranking_df.iloc[0]['Modelo']\n",
        "best_model_score = ranking_df.iloc[0]['Score_Composto']\n",
        "\n",
        "print(f\"Modelo com melhor score composto: {best_model_name}\")\n",
        "print(f\"Score: {best_model_score:.2f}\")\n",
        "print(\"\\\\nCritérios de seleção:\")\n",
        "print(\"- AUC-ROC: Capacidade geral de discriminação\")\n",
        "print(\"- AUC-PR: Precisão média (importante para classes desbalanceadas)\")\n",
        "print(\"- F1-Score: Equilíbrio entre precisão e recall\")\n",
        "print(\"- Recall: Capacidade de identificar casos positivos\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Seleção do Melhor Modelo e Previsão para Novo Usuário\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Seleção do melhor modelo baseado no ranking\n",
        "print(\"=== SELEÇÃO DO MELHOR MODELO ===\")\n",
        "\n",
        "# Definir o melhor modelo baseado no ranking\n",
        "if best_model_name == 'Random Forest':\n",
        "    best_model = rf_model\n",
        "    best_model_scaled = False\n",
        "elif best_model_name == 'Regressão Logística':\n",
        "    best_model = lr_model\n",
        "    best_model_scaled = True\n",
        "elif best_model_name == 'Gradient Boosting':\n",
        "    best_model = gb_model\n",
        "    best_model_scaled = False\n",
        "else:  # SVM\n",
        "    best_model = svm_model\n",
        "    best_model_scaled = True\n",
        "\n",
        "print(f\"Modelo selecionado: {best_model_name}\")\n",
        "print(f\"Usa dados normalizados: {best_model_scaled}\")\n",
        "\n",
        "# Treinar o modelo final com todos os dados de treino\n",
        "if best_model_scaled:\n",
        "    best_model.fit(X_train_scaled, y_train)\n",
        "    X_final = X_train_scaled\n",
        "else:\n",
        "    best_model.fit(X_train, y_train)\n",
        "    X_final = X_train\n",
        "\n",
        "print(\"\\\\nModelo treinado com sucesso!\")\n",
        "print(f\"Número de features: {X_final.shape[1]}\")\n",
        "print(f\"Número de amostras de treino: {X_final.shape[0]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Função para fazer previsão para um novo usuário\n",
        "def predict_new_user(user_data, model, scaler=None, use_scaled=False):\n",
        "    \\\"\\\"\\\"\n",
        "    Faz previsão para um novo usuário\n",
        "    \n",
        "    Args:\n",
        "        user_data: dict com os dados do usuário\n",
        "        model: modelo treinado\n",
        "        scaler: scaler usado (se necessário)\n",
        "        use_scaled: se deve usar dados normalizados\n",
        "    \n",
        "    Returns:\n",
        "        prediction: previsão (0 ou 1)\n",
        "        probability: probabilidade de ser classe positiva\n",
        "    \\\"\\\"\\\"\n",
        "    \n",
        "    # Criar DataFrame com os dados do usuário\n",
        "    user_df = pd.DataFrame([user_data])\n",
        "    \n",
        "    # Aplicar o mesmo tratamento dos dados originais\n",
        "    # Tratamento de valores 'unknown'\n",
        "    if 'default' in user_df.columns and user_df['default'].iloc[0] == 'unknown':\n",
        "        user_df['default'] = 'no'\n",
        "    if 'education' in user_df.columns and user_df['education'].iloc[0] == 'unknown':\n",
        "        user_df['education'] = 'basic.4y'\n",
        "    \n",
        "    # Encoding das variáveis categóricas\n",
        "    for var in categorical_vars_to_encode:\n",
        "        if var in user_df.columns:\n",
        "            user_df[var + '_encoded'] = label_encoders[var].transform(user_df[var])\n",
        "    \n",
        "    # Selecionar as features na mesma ordem\n",
        "    user_features = user_df[feature_columns]\n",
        "    \n",
        "    # Normalizar se necessário\n",
        "    if use_scaled:\n",
        "        user_features = scaler.transform(user_features)\n",
        "    \n",
        "    # Fazer previsão\n",
        "    prediction = model.predict(user_features)[0]\n",
        "    probability = model.predict_proba(user_features)[0][1]\n",
        "    \n",
        "    return prediction, probability\n",
        "\n",
        "print(\"Função de previsão criada com sucesso!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exemplo de previsão para um novo usuário\n",
        "print(\"=== EXEMPLO DE PREVISÃO PARA NOVO USUÁRIO ===\")\n",
        "\n",
        "# Dados de exemplo de um novo usuário\n",
        "new_user = {\n",
        "    'age': 35,\n",
        "    'job': 'admin.',\n",
        "    'marital': 'married',\n",
        "    'education': 'university.degree',\n",
        "    'default': 'no',\n",
        "    'housing': 'yes',\n",
        "    'loan': 'no',\n",
        "    'contact': 'cellular',\n",
        "    'month': 'aug',\n",
        "    'day_of_week': 'fri',\n",
        "    'duration': 300,  # Será ignorado na previsão (não está no treino)\n",
        "    'campaign': 1,\n",
        "    'pdays': 999,\n",
        "    'previous': 0,\n",
        "    'poutcome': 'nonexistent',\n",
        "    'emp.var.rate': -1.8,\n",
        "    'cons.price.idx': 92.893,\n",
        "    'cons.conf.idx': -46.2,\n",
        "    'euribor3m': 1.299,\n",
        "    'nr.employed': 5099.1\n",
        "}\n",
        "\n",
        "print(\"Dados do novo usuário:\")\n",
        "for key, value in new_user.items():\n",
        "    print(f\"{key}: {value}\")\n",
        "\n",
        "# Fazer previsão\n",
        "prediction, probability = predict_new_user(\n",
        "    new_user, \n",
        "    best_model, \n",
        "    scaler if best_model_scaled else None, \n",
        "    best_model_scaled\n",
        ")\n",
        "\n",
        "print(f\"\\\\n=== RESULTADO DA PREVISÃO ===\")\n",
        "print(f\"Previsão: {'SIM' if prediction == 1 else 'NÃO'} (subscreverá ao produto)\")\n",
        "print(f\"Probabilidade: {probability:.3f} ({probability*100:.1f}%)\")\n",
        "\n",
        "if probability > 0.5:\n",
        "    print(\"\\\\nRecomendação: Este cliente tem alta probabilidade de subscrever ao produto.\")\n",
        "    print(\"Ação sugerida: Priorizar este cliente na campanha de marketing.\")\n",
        "else:\n",
        "    print(\"\\\\nRecomendação: Este cliente tem baixa probabilidade de subscrever.\")\n",
        "    print(\"Ação sugerida: Focar em outros clientes com maior potencial.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Conclusões e Impactos de Negócio\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Principais Descobertas da Análise\n",
        "\n",
        "1. **Características da Base de Dados:**\n",
        "   - Total de 41.188 registros com 20 features\n",
        "   - Base altamente desbalanceada: apenas ~11% dos clientes subscreveram ao produto\n",
        "   - Presença de valores 'unknown' em algumas variáveis categóricas\n",
        "   - Variáveis econômicas (indicadores macroeconômicos) presentes\n",
        "\n",
        "2. **Tratamento de Dados Realizado:**\n",
        "   - Substituição de valores 'unknown' por valores mais conservadores\n",
        "   - Encoding de variáveis categóricas usando LabelEncoder\n",
        "   - Normalização dos dados para algoritmos sensíveis à escala\n",
        "   - Manutenção de outliers (podem representar casos importantes)\n",
        "\n",
        "3. **Modelos Testados:**\n",
        "   - Regressão Logística (com class_weight='balanced')\n",
        "   - Random Forest (com class_weight='balanced')\n",
        "   - Gradient Boosting\n",
        "   - Support Vector Machine (com class_weight='balanced')\n",
        "\n",
        "4. **Critérios de Avaliação:**\n",
        "   - AUC-ROC: Capacidade geral de discriminação\n",
        "   - AUC-PR: Precisão média (melhor para classes desbalanceadas)\n",
        "   - F1-Score: Equilíbrio entre precisão e recall\n",
        "   - Recall: Capacidade de identificar casos positivos\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Impactos de Negócio\n",
        "\n",
        "**1. Otimização de Recursos de Marketing:**\n",
        "- O modelo permite identificar clientes com maior probabilidade de subscrever\n",
        "- Redução significativa de custos de marketing ao focar nos clientes certos\n",
        "- Aumento da eficiência das campanhas telefônicas\n",
        "\n",
        "**2. Melhoria na Experiência do Cliente:**\n",
        "- Clientes com baixa probabilidade não serão incomodados com ligações desnecessárias\n",
        "- Clientes com alta probabilidade receberão atenção prioritária\n",
        "- Personalização das abordagens baseada no perfil do cliente\n",
        "\n",
        "**3. Aumento da Taxa de Conversão:**\n",
        "- Foco nos clientes mais propensos a subscrever\n",
        "- Melhoria na taxa de sucesso das campanhas\n",
        "- Otimização do tempo dos agentes de vendas\n",
        "\n",
        "**4. Tomada de Decisão Estratégica:**\n",
        "- Insights sobre quais características dos clientes são mais importantes\n",
        "- Identificação de padrões comportamentais\n",
        "- Suporte para estratégias de retenção e aquisição\n",
        "\n",
        "**5. Monitoramento Contínuo:**\n",
        "- O modelo pode ser atualizado periodicamente com novos dados\n",
        "- Acompanhamento da performance ao longo do tempo\n",
        "- Ajustes estratégicos baseados em resultados\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Limitações e Considerações Futuras\n",
        "\n",
        "**Limitações do Modelo:**\n",
        "1. **Base Desbalanceada:** Apesar das técnicas aplicadas, a alta desproporção entre classes pode afetar a performance\n",
        "2. **Dados Históricos:** O modelo é baseado em dados passados e pode não refletir mudanças no comportamento do mercado\n",
        "3. **Variáveis Econômicas:** Indicadores macroeconômicos podem ter mudado significativamente desde a coleta dos dados\n",
        "4. **Threshold Fixo:** O modelo usa threshold 0.5, mas este pode ser otimizado para diferentes objetivos de negócio\n",
        "\n",
        "**Melhorias Futuras:**\n",
        "1. **Técnicas de Balanceamento:** Implementar SMOTE ou outras técnicas de oversampling\n",
        "2. **Feature Engineering:** Criar novas variáveis derivadas das existentes\n",
        "3. **Ensemble Methods:** Combinar múltiplos modelos para melhor performance\n",
        "4. **Threshold Optimization:** Ajustar o threshold baseado no custo-benefício do negócio\n",
        "5. **Validação Temporal:** Implementar validação temporal para simular cenários reais\n",
        "\n",
        "**Recomendações para Implementação:**\n",
        "1. **Teste A/B:** Implementar gradualmente com grupos de controle\n",
        "2. **Monitoramento:** Acompanhar métricas de negócio além das métricas técnicas\n",
        "3. **Feedback Loop:** Coletar feedback dos agentes de vendas sobre a qualidade das previsões\n",
        "4. **Atualização Regular:** Retreinar o modelo periodicamente com novos dados\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Resumo Executivo\n",
        "\n",
        "Este projeto desenvolveu um modelo de classificação para prever a probabilidade de clientes subscreverem a um produto bancário (depósito a prazo). \n",
        "\n",
        "**Principais Resultados:**\n",
        "- ✅ Análise exploratória completa dos dados\n",
        "- ✅ Tratamento adequado de valores missing e outliers\n",
        "- ✅ Implementação e comparação de 4 modelos diferentes\n",
        "- ✅ Avaliação considerando o desbalanceamento da base\n",
        "- ✅ Seleção do melhor modelo baseado em critérios técnicos\n",
        "- ✅ Sistema de previsão para novos usuários\n",
        "\n",
        "**Modelo Selecionado:** O modelo com melhor performance geral foi selecionado baseado em um score composto considerando AUC-ROC, AUC-PR, F1-Score e Recall.\n",
        "\n",
        "**Impacto Esperado:** \n",
        "- Redução de custos de marketing através de targeting mais eficiente\n",
        "- Aumento da taxa de conversão das campanhas\n",
        "- Melhoria na experiência do cliente\n",
        "- Suporte para decisões estratégicas baseadas em dados\n",
        "\n",
        "O modelo está pronto para implementação e pode ser facilmente integrado aos sistemas existentes do banco para otimizar as campanhas de marketing.\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
